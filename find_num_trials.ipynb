{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6721904",
   "metadata": {},
   "source": [
    "Often when running experiments, we have no idea how many trials we need to run (Section 11.2.2 of *Mathematical Statistics and Data Analysis* by John Rice discusses this as well). However, we can determine the least number of samples to achieve our specifications using a two-sided t-test (a statistical test for different means using the Neyman-Pearson criterion).\n",
    "\n",
    "A t-test is formulated as \n",
    "\n",
    "$$\n",
    "t_i = \\frac{\\bar{x} - \\bar{y}}{s/\\sqrt{n}}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "|t_i|  > \\gamma \\implies \\text{accept } H_1 \\\\\n",
    "|t_i|  < \\gamma \\implies \\text{accept } H_0 \\\\\n",
    "$$\n",
    "\n",
    "such that $\\bar{x}$ and $\\bar{y}$ are sample averages, $s$ is the population standard deviation, $n$ is the number of samples (or degrees of freedom), $H_1$ is the alternative hypothesis, and $H_0$ is the null hypothesis. \n",
    "\n",
    "Under the null hypothesis $H_0$, $x \\sim \\mathcal{N}(\\mu, s^2)$ and $y \\sim \\mathcal{N}(\\mu, s^2)$, then $t$ is distributed according to a Student-t distribution.\n",
    "\n",
    "Under the alternative hypothesis $H_1$, $x \\sim \\mathcal{N}(\\mu_x, s^2)$ and $y \\sim \\mathcal{N}(\\mu_y, s^2)$, then $t$ is distributed accordining to a non-central Student-t distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e2ba42",
   "metadata": {},
   "source": [
    "In the Neyman-Pearson criterion, the goal is to maximize the probability of detection $P(H_1 | H_1)$ or power $\\Beta$ given a probability of false-positives $P(H_1|H_0)$ or size $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3023dcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect size (Cohen's d): 5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import nct\n",
    "\n",
    "alpha = 0.05\n",
    "beta = 0.8\n",
    "delta_mean = 2.5\n",
    "sigmax = 0.5\n",
    "sigmay = 0.5\n",
    "pooled_sample_variance = (sigmax**2 + sigmay**2) / 2 # Assume same number of trials for each population\n",
    "cohens_d = delta_mean / np.sqrt(pooled_sample_variance)\n",
    "print(f\"Effect size (Cohen's d): {cohens_d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a82d30c",
   "metadata": {},
   "source": [
    "Given these inputs, we calculate the threshold $\\gamma$ using different $n$ and terminate when we reach the desired power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20d2c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcBeta(N: float, verbose: bool = False):\n",
    "    # Calculate threshold for Neyman-Pearson test to ensure \n",
    "    # the probability of false alarm given P(|test_statistic| > gamma | H_0) = alpha\n",
    "    gamma = nct.ppf(1 - alpha/2, N-1, 0.0)\n",
    "    if verbose:\n",
    "        print(f\"Threshold for two-sided t-test: {gamma}\")\n",
    "\n",
    "    # Calculate power or probability of detection (cohens_d makes the t-distribution a non-central t-distribution)\n",
    "    ncp = np.sqrt(N) * cohens_d\n",
    "    upper_prob = 1.0 - nct.cdf(gamma, N-1, ncp) # P(t > gamma| H_1)\n",
    "    lower_prob = nct.cdf(-gamma, N-1, ncp) # P(t < gamma | H_1)\n",
    "    if verbose:\n",
    "        print(f\"Power (or probability of detection): {upper_prob + lower_prob}\")\n",
    "    return upper_prob + lower_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b3431f",
   "metadata": {},
   "source": [
    "Use bisection algorithm to quickly find the best $n$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90559c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.491 samples gives a test with power 0.800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MAX_N = 1000\n",
    "MIN_N = 2\n",
    "ERROR = 1e-3\n",
    "# Assume beta is smallest at MIN_N and largest at MAX_N\n",
    "\n",
    "max_n = MAX_N\n",
    "min_n = MIN_N\n",
    "it = 0\n",
    "while True:\n",
    "    n_proposal = (max_n + min_n) / 2.0\n",
    "    beta_n_proposal = calcBeta(n_proposal)\n",
    "    if abs(beta_n_proposal - beta) > ERROR and abs(n_proposal - MIN_N) > ERROR and abs(n_proposal - MAX_N) > ERROR:\n",
    "        if beta_n_proposal > beta:\n",
    "            max_n = n_proposal\n",
    "        else:\n",
    "            min_n = n_proposal\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(f\"{n_proposal:0.3f} samples gives a test with power {beta_n_proposal:0.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
